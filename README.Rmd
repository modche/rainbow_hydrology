---
title: "Color-issues in hydrological publications"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(pillar.min_chars = 15)
```

**Authors**: Michael Stoelzle, University Freiburg, Germany and Lina Stein, University Bristol, UK

**Summary**: The rainbow color map is scientifically incorrect and hinders people with color vision deficiency to view visualizations in a correct way. Due to perceptual non-uniform color gradients within the rainbow color map the data representation is distorted what can lead to misinterpretation of results and flaws in science communication. Here we present the data of a paper survey of 797 scientific publication in the journal Hydrology and Earth System Sciences. With in the survey all papers were classified according to color issues. Find details about the data below.

**Kaggle**: There is also a Kaggle notebook available (https://www.kaggle.com/modche/rainbow-papersurvey-hydrology) to load the survey data and to look into the data. 

## Load data frame

```{r load_packages, message=FALSE, warning=FALSE}
#install.packages("tidyverse")
library(tidyverse)
```

```{r read_data, message=FALSE}
#read data remotely from github
file <- 'https://raw.githubusercontent.com/modche/rainbow_hydrology/main/hess_papers_rainbow.txt'

df <- read_tsv(file)

# read file with base R
#df_alternative <- read.delim(file, sep = "\t")
```

## 1. Overview data variables of paper survey

-   `year` = year of publication (YYYY)
-   `date` = date (YYYY-MM-DD) of publication
-   `title` = full paper title from journal website
-   `authors` = list of authors comma-separated
-   `n_authors` = number of authors (integer between 1 and 27)
-   `col_code` = color-issue classification (see below)
-   `volume` = Journal volume
-   `start_page` = first page of paper (consecutive)
-   `end_page` = last page of paper (consecutive)
-   `base_url` = base url to access the PDF of the paper with `/volume/start_page/year/`
-   `filename` = specific file name of the paper PDF (e.g. `hess-9-111-2005.pdf`)

```{r structure}
str(df)
head(df)
tail(df)
skimr::skim(df)
```

### 2. Explanatory data analysis

Distribution of surveyed papers in 2005, 2010, 2015 and 2020.

```{r}
df %>% count(year)
```

Color classification is stored in the `col_code` variable with:

-   `0` = chromatic and issue-free,
-   `1` = red-green issues,
-   `2`= rainbow issues and
-   `bw`= black and white paper.

```{r col_code}
df %>% 
    count(col_code) %>% 
    mutate(pct = n / sum(n))
```

Focus on color classification in 2020:

```{r col_code_2020}
df %>% 
    group_by(year) %>% 
    count(col_code) %>% 
    mutate(pct = n / sum(n)) %>% 
    filter(year == 2020) %>% 
    ungroup()
```

Figure showing number of authors across color classification.

```{r col_code_fig, fig.height = 2.5, echo = FALSE}
ggplot(data = df) +
    geom_histogram(aes(x = n_authors), 
                   fill = "grey30", 
                   binwidth = 1, 
                   colour = "white",
                   size=.5) +
    facet_wrap(~col_code, nrow = 1) +
    theme_bw(14) +
    theme(panel.grid = element_blank())
    
```

### 3. Access PDF papers with download links

Data frame can be accessed to extract a vector of links to download specific papers.

**Example:** Access a specific paper from 2005:

```{r}
df %>% filter(year == 2005, start_page == 111) %>% 
    select(base_url, filename) %>% 
    mutate(download_link = paste0(base_url, filename)) %>% 
    pull(download_link)
```

**Example:** Single-author papers from 2005 that are pure black and white papers:

```{r}
df %>% filter(year == 2005, col_code == "bw", n_authors == 1) %>% 
    select(base_url, filename) %>% 
    mutate(download_link = paste0(base_url, filename)) %>% 
    pull(download_link)
```

**Example**: Rainbow papers from 2020 with more than 10 authors:

```{r}
df %>% filter(year == 2020, col_code == 2, n_authors > 10) %>% 
    select(base_url, filename) %>% 
    mutate(download_link = paste0(base_url, filename)) %>% 
    pull(download_link)
```

### 4. Potential analyses with paper survey data:

```{r pot_analyses}
df %>% filter(str_detect(string = authors, pattern = "Weiler"))
df %>% filter(str_detect(string = title, pattern = "radar"))
df %>% filter(n_authors >= 7, col_code == 2)
df %>% filter(end_page > start_page + 30)
```

### 5. Text mining

Code example to start with text mining, e.g. extracting common words in paper titles.

```{r text_mining}
library(tidytext)

df %>% 
    unnest_tokens(word, title) %>% 
	select(col_code, word, n_authors) %>% 
	mutate(word_len = str_length(word)) %>% 
	filter(word_len >= 5) %>% 
    group_by(word) %>% 
	add_count() %>% 
    ungroup()

```
